import React from 'react';
import './Modelos.css';
import TituloM from './ComponenM/TituloM/TituloM'
import LabelM from './ComponenM/LabelM/LabelM'
import arqui from './images/arqui.png';
import desenet from './images/desenet.png';
import unetDemo from './images/unetDemo.gif';
import {Link} from 'react-router-dom';

 const Modelos=() =>{

    return (
        <div className='model'>
            <TituloM text='uniMedic-Modelos'/>
            <LabelM text=''/>
            <LabelM text='Los modelos de uniMedic son los m√≥dulos de PyTorch üî• que se utilizan actualmente en uniMedic-Core,'/>
            <LabelM text='entrenados en conjuntos de datos disponibles p√∫blicamente.'/>
            <LabelM text='Cada modelo tiene una breve explicaci√≥n a continuaci√≥n y un ejemplo de c√≥mo hacer inferencias sobre el modelo.'/>
            <TituloM text='Visual Question Answering ‚ùì'/>
            <LabelM text=''/>
            <LabelM text='Visual Question Answering es una tarea desafiante para el aprendizaje autom√°tico moderno. Requiere un sistema de'/>
            <LabelM text='inteligencia artificial que pueda comprender tanto el texto como el idioma, de modo que pueda responder preguntas'/>
            <LabelM text='basadas en texto dado el contexto visual (una imagen, una tomograf√≠a computarizada, una resonancia magn√©tica, etc.).'/>
            <LabelM text='Arquitectura del modelo VQA: '/>
            <img src={arqui} className='image'/>
            <TituloM text='Segmentaci√≥n Cerebral M√©dica üß†'/>
            <LabelM text=''/>
            <LabelM text='La segmentaci√≥n m√©dica es la tarea de resaltar una regi√≥n o un conjunto de regiones con una propiedad espec√≠fica'/>
            <LabelM text='Nuestro modelo usa una arquitectura UNet, una red residual basada en downsampling y upsampling que tiene un'/>
            <LabelM text='buen desempe√±o en la localizaci√≥n de diferentes caracter√≠sticas, como se presenta en PyTorch hub, gracias al trabajo'/>
            <LabelM text='de Mateusz Buda.'/>
            <LabelM text='A continuaci√≥n se muestra una tarea de segmentaci√≥n cerebral: '/>
            
            <br />
            <img src={unetDemo} width='40%' height='200px' className='image'/>
            <br />
            <TituloM text=''/> 
            <TituloM text='Etiquetado M√©dico üìù'/>
            <LabelM text=''/>
            <LabelM text='El etiquetado m√©dico es la tarea de elegir qu√© tipo de imagen el usuario est√° introduciendo en la aplicaci√≥n, las'/>
            <LabelM text='posibles etiquetas son cerebro, pecho, mama, ojos, coraz√≥n, codo, antebrazo, mano, h√∫mero, hombro, mu√±eca.'/>
            <LabelM text='Actualmente, nuestro modelo VQA tiene soporte solo para cerebro y pecho (tor√°x), pero estamos trabajando para'/>
            <LabelM text='agregar soporte a m√∫ltiples etiquetas.'/>
            <LabelM text='A continuaci√≥n se muestra la arquitectura de Densenet121: '/>
            <img src={desenet}  className='image'/>
            <TituloM text=''/> 
            <TituloM text='Filtrado M√©dico üö´'/>
            <LabelM text=''/>
            <LabelM text='El filtrado m√©dico es la tarea de etiquetar im√°genes en dos conjuntos, m√©dicos y no m√©dicos, ya que queremos filtrar'/>
            <LabelM text='todos los no m√©dicos para que no se incluyan en los otros modelos de aprendizaje autom√°tico.'/>
            <LabelM text='Nuestro modelo utiliza la misma arquitectura Densenet121 del m√≥dulo torchvision.'/>
            <TituloM text='Datasets ‚úîÔ∏è'/>
            <LabelM text='Los conjuntos de datos utilizados en este proyecto son una versi√≥n aumentada de:'/>
            <LabelM href="https://www.nature.com/articles/sdata2018251#data-citations" text='-VQA-RAD'/>
            <LabelM href="https://www.kaggle.com/c/tiny-imagenet" text='-Tiny ImageNet'/>
            <LabelM href="http://medicaldecathlon.com/" text='-Medical Decathlon'/>
            <br />
            <br/>
            <p><a href="https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz">-Mednist</a>'- el conjunto de datos est√° amablemente disponible por <a href="https://www.mayo.edu/research/labs/radiology-informatics/overview">Dr. Bradley J. Erickson M.D., Ph.D.</a>
            '-(Departamento de Radiolog√≠a, Cl√≠nica Mayo) bajo licencia Creative Commons <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0.</a>
            </p>
            


        </div>
    )
};
export default Modelos;